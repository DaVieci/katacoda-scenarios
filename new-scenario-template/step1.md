This step will give you an introduction to Apache Spark and show you why the tool is so commonly used today.

# What is that?

Apache Spark is an unified analytics engine that is mainly used to process a large amount of data. The tool is written in Scala which is a functional-based programming language. Scala is the reason why Apache Spark can process data extremly fast since it gives spark the abilities to do parallel processing and in-memory computations (Kakarla et al., 2021, p. 29-30). 

# Why is it used?

Spark provides libraries such as SQL and DataFrames, MLlib for machine learning, GraphX for graph processing, and Spark Streaming (Kakarla et al., 2021, p. 30). These terms might sound unfamiliar to you, but are regularly used by data scientists and data engineers at their daily work. Furthermore, the speed and the use for data transformations on large datasets makes Spark a preferred tool when it comes to working with data in general.

Moreover, Apache Spark provides APIs for several programming languages. We are going to use the API dedicated for Python called `PySpark` in this katacoda scenario.