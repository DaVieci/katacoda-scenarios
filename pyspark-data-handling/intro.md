# Data Handling in PySpark compared to Python

Welcome to the katakoda scenario "Data Handling in PySpark compared to Python"!

## Abstract
Data has become a huge topic in our digital world nowadays. Dealing with it can sometimes be a tedious and time-consuming job since the data can change rapidly or grow very fast in a short time. Think about certain kinds of health data which are tracked by a smartwatch you wear while you are going for a jog or shopping data from online stores that tries to figure out your purchasing behaviour. These forms of data can make the data handling difficult. However, Apache Spark was created to make the processing of those kinds of data more convinient. 
In this katacoda scenario, one will learn how to access and transform data from different files using Apache Spark. Moreover, one will see how that data handling would be done in Python in contrast to the approach in PySpark. 

## Learning Objective

- Read data from text files and csv files
- Perform different kinds of operations on that data
- Understand the differences between PySpark and Python when working with data

## Prerequisite Skills

This katacoda was mainly created for computer science students or ongoing data scientists with prior experience using Python.

## Table of Contents

- Apache Spark
- Setting Up Environment
- Reading and Accessing Data
- Viewing Data
- Filtering Data
- Transforming Data
- Writing and Saving Data


